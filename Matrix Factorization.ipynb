{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/wearly_data/wear_train.csv',index_col=0) #train 0.9\n",
    "test = pd.read_csv('./data/wearly_data/wear_test.csv',index_col=0) #test 0.1\n",
    "wear_rate = pd.read_csv('./data/wearly_data/wear_rate.csv',index_col = 0) #total\n",
    "wear_item = pd.read_csv('./data/wearly_data/wear_item.csv',index_col = 0) #item\n",
    "wear_user = pd.read_csv('./data/wearly_data/wear_user.csv',index_col=0) #user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test ,rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>rate</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/m...</td>\n",
       "      <td>2</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/m...</td>\n",
       "      <td>3</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/m...</td>\n",
       "      <td>2</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/m...</td>\n",
       "      <td>1</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/m...</td>\n",
       "      <td>3</td>\n",
       "      <td>4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30585</th>\n",
       "      <td>101</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/s...</td>\n",
       "      <td>1</td>\n",
       "      <td>6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30586</th>\n",
       "      <td>28</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/o...</td>\n",
       "      <td>2</td>\n",
       "      <td>4928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30587</th>\n",
       "      <td>237</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/f...</td>\n",
       "      <td>3</td>\n",
       "      <td>3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30588</th>\n",
       "      <td>11</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30589</th>\n",
       "      <td>298</td>\n",
       "      <td>https://wearlyimages.s3.amazonaws.com/wearly/f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30590 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                    image_file_name  rate  image_id\n",
       "0       262  https://wearlyimages.s3.amazonaws.com/wearly/m...     2      4148\n",
       "1       285  https://wearlyimages.s3.amazonaws.com/wearly/m...     3      4148\n",
       "2       130  https://wearlyimages.s3.amazonaws.com/wearly/m...     2      4148\n",
       "3        11  https://wearlyimages.s3.amazonaws.com/wearly/m...     1      4148\n",
       "4       195  https://wearlyimages.s3.amazonaws.com/wearly/m...     3      4148\n",
       "...     ...                                                ...   ...       ...\n",
       "30585   101  https://wearlyimages.s3.amazonaws.com/wearly/s...     1      6047\n",
       "30586    28  https://wearlyimages.s3.amazonaws.com/wearly/o...     2      4928\n",
       "30587   237  https://wearlyimages.s3.amazonaws.com/wearly/f...     3      3162\n",
       "30588    11  https://wearlyimages.s3.amazonaws.com/wearly/l...     1      4057\n",
       "30589   298  https://wearlyimages.s3.amazonaws.com/wearly/f...     2      2209\n",
       "\n",
       "[30590 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wear_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7493"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wear_rate.image_file_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = wear_user.user.nunique() #307개\n",
    "ITEM_NUM = wear_item.image_file_name.nunique() #7628개\n",
    "\n",
    "AdjacencyUsers = np.zeros((USER_NUM,ITEM_NUM), dtype=np.float32) # N x M shape의 zero matrix 생성 (Adjacency)\n",
    "DegreeUsers = np.zeros((USER_NUM,1), dtype=np.float32) #N x 1  shape의 zero vactor 생성 (Degree)\n",
    "\n",
    "AdjacencyItems = np.zeros((ITEM_NUM,USER_NUM), dtype=np.float32) # M x N shape의 zero matrix 생성\n",
    "DegreeItems =  np.zeros((ITEM_NUM,1), dtype=np.float32)  # M X 1 shape의 zero vactor 생성\n",
    "\n",
    "for index, row in wear_rate.iterrows():\n",
    "    userid=int(row['user'])\n",
    "    itemid=int(row['image_id'])\n",
    "    AdjacencyUsers[userid][itemid]=row['rate']\n",
    "    AdjacencyItems[itemid][userid]=row['rate']\n",
    "    DegreeUsers[userid][0]+=1\n",
    "    DegreeItems[itemid][0]+=1\n",
    "    \n",
    "rating_df = pd.DataFrame(AdjacencyUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7618</th>\n",
       "      <th>7619</th>\n",
       "      <th>7620</th>\n",
       "      <th>7621</th>\n",
       "      <th>7622</th>\n",
       "      <th>7623</th>\n",
       "      <th>7624</th>\n",
       "      <th>7625</th>\n",
       "      <th>7626</th>\n",
       "      <th>7627</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 7628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  7618  \\\n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "302   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "303   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "304   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "305   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "306   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "     7619  7620  7621  7622  7623  7624  7625  7626  7627  \n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "302   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "303   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "304   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "305   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "306   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[307 rows x 7628 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k)) #행렬 P\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k)) #행렬 Q\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)]) #평가가 된 값들의 평균값을 사용\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            for i in range(self._num_users):\n",
    "                for j in range(self._num_items):\n",
    "                    if self._R[i, j] > 0:\n",
    "                        self.gradient_descent(i, j, self._R[i, j]) #rating이 존재하는경우만\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(cost / len(xi))\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "        print fit results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"User Latent P:\")\n",
    "        print(self._P)\n",
    "        print(\"Item Latent Q:\")\n",
    "        print(self._Q.T)\n",
    "        print(\"P x Q:\")\n",
    "        print(self._P.dot(self._Q.T))\n",
    "        print(\"bias:\")\n",
    "        print(self._b)\n",
    "        print(\"User Latent bias:\")\n",
    "        print(self._b_P)\n",
    "        print(\"Item Latent bias:\")\n",
    "        print(self._b_Q)\n",
    "        print(\"Final R matrix:\")\n",
    "        print(self.get_complete_matrix())\n",
    "        print(\"Final RMSE:\")\n",
    "        print(self._training_process[self._epochs-1][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.5798\n",
      "Iteration: 20 ; cost = 0.5456\n",
      "Iteration: 30 ; cost = 0.5284\n",
      "Iteration: 40 ; cost = 0.5184\n",
      "Iteration: 50 ; cost = 0.5117\n",
      "User Latent P:\n",
      "[[ 6.98514013e-02  3.58490180e-02 -5.74746523e-02 -1.94961721e-01\n",
      "   1.07354756e-01]\n",
      " [ 2.92582778e-02  8.72866870e-02  9.70787900e-05  2.93261717e-03\n",
      "  -1.13806732e-01]\n",
      " [-4.53420142e-03 -2.11186626e-02 -2.88798311e-03 -8.90915132e-02\n",
      "   7.19052992e-02]\n",
      " ...\n",
      " [ 2.02941461e-01 -1.02664196e-01  1.98127457e-02  1.02772657e-01\n",
      "  -9.71017093e-02]\n",
      " [-1.23634926e-01 -4.53685410e-02  1.15346709e-01 -6.65801930e-03\n",
      "  -1.21521324e-03]\n",
      " [ 2.70496719e-02 -9.12858764e-02 -2.81961028e-02 -8.63376599e-02\n",
      "   7.77348991e-02]]\n",
      "Item Latent Q:\n",
      "[[ 0.79871368  0.09697732 -2.30129734 ... -0.22610661 -1.83180982\n",
      "  -0.61081322]\n",
      " [-0.51529981  1.20465008 -0.33877559 ...  0.57146258  0.95431806\n",
      "  -0.77407098]\n",
      " [ 0.12403989  1.48630274 -1.50858852 ... -0.18827175 -0.81728422\n",
      "   1.26340056]\n",
      " [-1.52870512 -1.06350638  0.45183094 ...  0.83703193 -0.3555674\n",
      "   0.71841405]\n",
      " [-0.47350777  0.67312567  0.95833197 ... -0.71798634 -0.43278301\n",
      "  -0.44983155]]\n",
      "P x Q:\n",
      "[[ 0.2773948   0.24414107 -0.07139626 ... -0.22475507 -0.02390927\n",
      "  -0.33138415]\n",
      " [ 0.02780748  0.0284065  -0.20478863 ...  0.12741368  0.0778352\n",
      "  -0.03201409]\n",
      " [ 0.10904962  0.11297796  0.05060066 ... -0.13669905 -0.00892918\n",
      "  -0.08088165]\n",
      " ...\n",
      " [ 0.10632186 -0.249207   -0.50875761 ...  0.04745636 -0.48043574\n",
      "   0.09805421]\n",
      " [-0.05030935  0.11105998  0.12170688 ... -0.02438874  0.09180191\n",
      "   0.25212884]\n",
      " [ 0.16032384 -0.00510627  0.04669822 ... -0.18105402 -0.11656487\n",
      "  -0.07847732]]\n",
      "bias:\n",
      "1.9524027\n",
      "User Latent bias:\n",
      "[-0.2259763   0.09124145  0.06946735  0.15798171  0.61016286 -0.2543786\n",
      "  0.10814087  0.20201953 -0.2757445   0.21619526  0.44287081 -0.0714544\n",
      "  0.14861606 -0.02959832  0.42678604 -0.54645675  0.26339455  0.25972346\n",
      "  0.22358657  0.52994479  0.20756996  0.30513302 -0.13266358 -0.24869788\n",
      "  0.07008898 -0.2875983   0.50807326  0.06569162 -0.07105524  0.21941835\n",
      " -0.12326981  0.05248117  0.03057794 -0.20912248 -0.10037103 -0.31993287\n",
      " -0.0800946   0.45254283 -0.47102977 -0.37929829 -0.50502182 -0.02373584\n",
      " -0.27154951  0.55408316 -0.12257883  0.00149841  0.15562587  0.33116521\n",
      "  0.17478932 -0.10831039  0.00155313  0.03130724 -0.45147235 -0.12342098\n",
      " -0.41818752 -0.29685721  0.02586892  0.22214336  0.37200855 -0.44268266\n",
      " -0.1283296  -0.02389113 -0.0350591  -0.06909639 -0.52679072  0.11314871\n",
      "  0.03368886 -0.10143706  0.05197279 -0.359881   -0.05308449 -0.2219857\n",
      "  0.12679626  0.11791356  0.11973352  0.16597795 -0.08802192  0.13874492\n",
      " -0.22838222 -0.13523173 -0.19285843 -0.24785949  0.22002549  0.25240526\n",
      "  0.14771097 -0.20627349 -0.0877644   0.03189451 -0.01685697  0.47927956\n",
      "  0.45881472  0.11582829 -0.35958555  0.31077865 -0.15745869  0.29836554\n",
      " -0.15436565 -0.13923951  0.00476371 -0.3170777  -0.3407546  -0.00536339\n",
      "  0.01040054  0.28319296 -0.05119188  0.2441772  -0.19823879 -0.57551633\n",
      " -0.06334305 -0.05127747 -0.2499696   0.18119536 -0.12512539 -0.2552427\n",
      " -0.09530642 -0.30832455  0.09767209 -0.1554153   0.25474244  0.12759849\n",
      "  0.46246271 -0.07836745  0.32436731 -0.09165113 -0.4622885  -0.13295788\n",
      "  0.17103517 -0.3692755   0.19881848  0.17069736  0.05357541  0.23545377\n",
      "  0.05681737  0.18519695  0.12965608 -0.10806829  0.17983435  0.03519795\n",
      " -0.0748326  -0.18025583 -0.09122071  0.0559617   0.12923059  0.15139268\n",
      "  0.1236151  -0.53134219  0.17928968 -0.22921407  0.10305765 -0.19822309\n",
      "  0.10574602 -0.55457752  0.29400296  0.18424406 -0.55884683 -0.09956426\n",
      " -0.02261537  0.22864215 -0.05807309 -0.69999253  0.11594331  0.11930179\n",
      " -0.45899557  0.08500271  0.18972198 -0.26618904  0.15449914  0.02025469\n",
      " -0.74271939 -0.02099272  0.19441235  0.07852329 -0.38831948  0.17243099\n",
      "  0.28655302  0.20517877 -0.59972422  0.10272049  0.07832335  0.06322266\n",
      " -0.32794329  0.00930739  0.10050869  0.08206823  0.13489753 -0.0601747\n",
      " -0.43943926 -0.20493662  0.24739373  0.09153076 -0.8064217   0.22153847\n",
      " -0.19370194  0.22118015 -0.74522399  0.35181339  0.12542773  0.06896302\n",
      " -0.10465048  0.16832635  0.05940388  0.10135871  0.2775239  -0.01554906\n",
      " -0.1753606  -0.01762472 -0.68012014 -0.09229563  0.34230858  0.11323873\n",
      "  0.09650231  0.26073095  0.14431949 -0.68954619  0.07422849  0.11357042\n",
      " -0.36528642  0.05164292 -0.1320761   0.0279646   0.02805286 -0.03450924\n",
      " -0.0058728  -0.68997669  0.20955528  0.13024658 -0.15025642 -0.76049591\n",
      "  0.24691921 -0.07422073 -0.0454285  -0.25388881  0.0956407   0.09093561\n",
      "  0.18562077  0.10403105 -0.19312849  0.29533697 -0.7514949  -0.11046632\n",
      "  0.4009292  -0.03670977  0.02977763 -0.37066     0.03339864 -0.14703416\n",
      "  0.43944115  0.0073109  -0.25482121 -0.25279061 -0.01450847  0.44875092\n",
      " -0.00747739 -0.69666846 -0.37357132 -0.15538306  0.15100148  0.03636721\n",
      " -0.59329401 -0.0482605   0.05854944  0.11508033  0.06000579 -0.01961279\n",
      "  0.47556994 -0.3049293   0.07258365  0.22771002  0.12515455  0.05796842\n",
      " -0.02998788 -0.02534928  0.27412545 -0.34912027 -0.34614276 -0.48076775\n",
      "  0.01784099  0.14788368  0.10567207 -0.19713303  0.13324743  0.23969405\n",
      "  0.18044427  0.04648203  0.2082192   0.18928957  0.09446335  0.39948539\n",
      "  0.26518427  0.31155392  0.35007242  0.38980352  0.60092983  0.50145337\n",
      "  0.24264044  0.37283724  0.15461232  0.22744697  0.2785524   0.22358311\n",
      "  0.24133216  0.29340883  0.36739419 -0.5800495   0.15796637  0.14285484\n",
      " -0.08467862]\n",
      "Item Latent bias:\n",
      "[ 0.30154358 -0.11959344  0.29453686 ...  0.28483053 -0.01379032\n",
      "  0.        ]\n",
      "Final R matrix:\n",
      "[[2.30536479 1.85097404 1.94956701 ... 1.78650187 1.68872682 1.39504226]\n",
      " [2.37299522 1.95245722 2.13339238 ... 2.45588836 2.10768903 2.01163006]\n",
      " [2.43246326 2.01525458 2.36700757 ... 2.17000153 1.99915056 1.9409884 ]\n",
      " ...\n",
      " [2.51823452 1.74156864 1.89614833 ... 2.44265597 1.61614302 2.2084233 ]\n",
      " [2.34649178 2.08672409 2.51150128 ... 2.35569933 2.17326913 2.34738639]\n",
      " [2.32959151 1.74302438 2.20895916 ... 1.9715006  1.7373689  1.78924677]]\n",
      "Final RMSE:\n",
      "0.511737428852716\n"
     ]
    }
   ],
   "source": [
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : 307 X 762)\n",
    "\n",
    "    # P, Q is (307 X k), (k X 7628) matrix\n",
    "    factorizer = MatrixFactorization(AdjacencyUsers, k=5, learning_rate=0.01, reg_param=0.01, epochs=50, verbose=True)\n",
    "    factorizer.fit()\n",
    "    factorizer.print_results()\n",
    "    final_df = factorizer.get_complete_matrix() #변환된 R_u,i matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117374288527157"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_RMSE(df1,df2):\n",
    "    raw = df1\n",
    "    pred = df2\n",
    "    \n",
    "    raw[raw ==0] = 'nan'\n",
    "    \n",
    "    return np.sqrt(np.nansum((raw - pred)**2 / np.isfinite(raw).sum()))\n",
    "    \n",
    "# train_df\n",
    "get_RMSE(AdjacencyUsers,final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117374288527157"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df\n",
    "get_RMSE(AdjacencyUsers,final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.30536479, 1.85097404, 1.94956701, ..., 1.78650187, 1.68872682,\n",
       "        1.39504226],\n",
       "       [2.37299522, 1.95245722, 2.13339238, ..., 2.45588836, 2.10768903,\n",
       "        2.01163006],\n",
       "       [2.43246326, 2.01525458, 2.36700757, ..., 2.17000153, 1.99915056,\n",
       "        1.9409884 ],\n",
       "       ...,\n",
       "       [2.51823452, 1.74156864, 1.89614833, ..., 2.44265597, 1.61614302,\n",
       "        2.2084233 ],\n",
       "       [2.34649178, 2.08672409, 2.51150128, ..., 2.35569933, 2.17326913,\n",
       "        2.34738639],\n",
       "       [2.32959151, 1.74302438, 2.20895916, ..., 1.9715006 , 1.7373689 ,\n",
       "        1.78924677]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
